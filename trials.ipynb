{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCN_model import GCN\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch_geometric.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ckaz3\\miniconda3\\envs\\grl_mini_project\\Lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.Planetoid(\n",
    "    root=\"./\",\n",
    "    name='Cora',\n",
    "    split=\"public\",\n",
    "    transform=torch_geometric.transforms.GCNNorm()\n",
    "  )\n",
    "print(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "        model,\n",
    "        data,\n",
    "        mask):\n",
    "    \n",
    "    edge_index = torch_geometric.EdgeIndex(dataset.edge_index)\n",
    "    adj_matrix = edge_index.to_dense()\n",
    "    \n",
    "    output = model(data.x, adj_matrix)\n",
    "\n",
    "    output = torch.argmax(output[mask], dim=1)\n",
    "    target = data.y[mask]\n",
    "\n",
    "    return torch.mean((output == target).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    num_layers: int,\n",
    "    aug_adj_type: str,\n",
    "    lr: int,\n",
    "    weight_decay: int,\n",
    "    num_epochs: int,\n",
    "    dataset,\n",
    "    verbose: bool = True\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    This function trains a node classification model and returns the trained model object.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    data = dataset.data\n",
    "    data = data.to(device)\n",
    "\n",
    "    # calculate adjacency matrix\n",
    "    edge_index = torch_geometric.EdgeIndex(dataset.edge_index)\n",
    "    adj_matrix = edge_index.to_dense()\n",
    "\n",
    "    model = GCN(\n",
    "        in_channels=dataset.num_features,\n",
    "        hidden_channels=64,\n",
    "        out_channels=dataset.num_classes,\n",
    "        num_layers=num_layers,\n",
    "        aug_adj_type=aug_adj_type,\n",
    "        dropout=0.3,\n",
    "    ).to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    early_stop_counter = 0\n",
    "    prev_val_acc = 1.1\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(data.x, adj_matrix)\n",
    "\n",
    "        loss = criterion(outputs[data.train_mask], data.y[data.train_mask])\n",
    "        losses.append(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # check for early-stopping\n",
    "        val_acc = evaluate(model, data, data.val_mask)\n",
    "\n",
    "        if val_acc < prev_val_acc:\n",
    "            if prev_val_acc != 1.1:\n",
    "                early_stop_counter += 1\n",
    "            prev_val_acc = val_acc\n",
    "\n",
    "            if early_stop_counter == 5:\n",
    "                break\n",
    "        else:\n",
    "            prev_val_acc = 1.1\n",
    "            early_stop_counter = 0\n",
    "\n",
    "        if i % 5 == 0 and verbose:\n",
    "            print(f\"Epoch: {i}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Epoch: {i}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:31<00:00, 45.73s/it]\n",
      "100%|██████████| 2/2 [00:28<00:00, 14.47s/it]\n",
      "100%|██████████| 2/2 [00:18<00:00,  9.03s/it]\n",
      "100%|██████████| 2/2 [00:45<00:00, 22.82s/it]\n",
      "100%|██████████| 4/4 [03:04<00:00, 46.03s/it]\n"
     ]
    }
   ],
   "source": [
    "layers = [0, 1] \n",
    "# layers.extend(np.arange(2, 12, 2))\n",
    "\n",
    "study_data = {\"symmetric\": {}, \"degree\": {}, \"adjacency\": {}, \"random walk\": {}}\n",
    "\n",
    "for aug_adj_type in tqdm(study_data):\n",
    "    for num_layers in tqdm(layers):\n",
    "        # train model\n",
    "        torch.manual_seed(2025) \n",
    "        model = train(\n",
    "            num_layers=num_layers,\n",
    "            aug_adj_type=aug_adj_type,\n",
    "            lr=0.001,\n",
    "            weight_decay=0.0001,\n",
    "            num_epochs=100,\n",
    "            dataset=dataset,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        data = dataset.data\n",
    "        data = data.to(device)\n",
    "\n",
    "        final_val_acc = evaluate(model, data, data.val_mask)\n",
    "\n",
    "        study_data[aug_adj_type][num_layers] = final_val_acc\n",
    "        \n",
    "        f = open(\"data.pkl\", \"wb\")\n",
    "        pickle.dump(study_data, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grl_mini_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
