{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    \"\"\"Implementation of a single graph convolutional layer.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        aug_adj_type (str): Type of augmented adjacency matrix to use\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, aug_adj_type: str):\n",
    "\n",
    "\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "\n",
    "        self.weight = nn.Parameter(torch.rand((in_channels, out_channels)) / 4 - 0.125)\n",
    "        self.aug_adj_type = aug_adj_type\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, adj_matrix: torch.Tensor):\n",
    "\n",
    "\n",
    "        degree_matrix = np.diag(np.sum(adj_matrix, axis=1))\n",
    "        num_nodes = len(adj_matrix)\n",
    "\n",
    "\n",
    "        if self.aug_adj_type == \"symmetric\":\n",
    "\n",
    "\n",
    "            aug_adj_matrix = (\n",
    "                np.power((degree_matrix + np.identity(num_nodes)), -0.5)\n",
    "                @ (aug_adj_matrix + np.identity(num_nodes))\n",
    "                @ np.power((degree_matrix + np.identity(num_nodes)), -0.5)\n",
    "            )\n",
    "        elif self.aug_adj_type == \"adjacency\":\n",
    "            aug_adj_matrix = adj_matrix\n",
    "        elif self.aug_adj_type == \"degree\":\n",
    "            aug_adj_matrix = degree_matrix\n",
    "        elif self.aug_adj_type == \"random walk\":\n",
    "            aug_adj_matrix = np.power(degree_matrix, -1) @ adj_matrix\n",
    "        else:\n",
    "            raise ValueError(\"Received invalid augmented adjacency matrix type.\")\n",
    "\n",
    "        x = F.relu(aug_adj_matrix @ x @ self.weight)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        dropout: float = 0.3,\n",
    "    ):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        if num_layers >= 2:\n",
    "            self.conv_layers.append(GCNLayer(in_channels, hidden_channels))\n",
    "\n",
    "            for i in range(num_layers - 2):\n",
    "                self.conv_layers.append(GCNLayer(hidden_channels, hidden_channels))\n",
    "\n",
    "            self.final_conv_layer = GCNLayer(hidden_channels, hidden_channels)\n",
    "        elif num_layers == 1:\n",
    "            self.final_conv_layer = GCNLayer(in_channels, hidden_channels)\n",
    "        else:  # num_layers == 0, single feed-forward network\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.rand((in_channels, hidden_channels)) / 4 - 0.125\n",
    "            )\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, adj_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        if self.num_layers >= 1:\n",
    "            for layer in self.conv_layers:\n",
    "                x = layer(x, adj_matrix)\n",
    "                x = F.dropout(x, p=self.dropout)\n",
    "\n",
    "            x = self.final_conv_layer(x, adj_matrix)\n",
    "\n",
    "        else:  # num_layers == 0, single feed-forward network\n",
    "            x = F.relu(x @ self.weight)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # def param_init(self):\n",
    "    #     for layer in self.conv_layers:\n",
    "    #         layer.reset_parameters()\n",
    "\n",
    "    #     if self.output_layer:\n",
    "    #         self.output_layer.reset_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grl_mini_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
